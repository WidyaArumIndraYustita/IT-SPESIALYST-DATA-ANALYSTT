# IT-SPESIALYST-DATA-ANALYSTT
# Import, Store, Export Data
Extract, transform, and load (ETL) is the process of combining data from various sources into a large central repository called a data warehouse. ETL uses a set of business rules to clean and organize raw data and prepare it for storage, data analytics, and machine learning (ML). You can meet specific business intelligence needs through data analytics (such as predicting the outcomes of business decisions, generating reports and dashboards, reducing operational inefficiencies, and more). The first stage of ETL is to perform Extract, which is a stage for retrieving data from existing data sources such as text files, spreadsheets, etc. For example, we have uploaded a CSV file in Jupiter which we put together in a PYTHON folder, secondly by carrying out a transformation, which involves processing and modification.
The data has been entered into Jupiter so that the data we will use is in accordance with the analysis needs. This data transformation is used to clean, combine and change
data structures if necessary. And the Load Stage is the stage of storing the processed data in the repository which will be used for further analysis. So at this load stage we can process the data that we have processed
Save it using the source code as above, in order to carry out further data analysis.
# Clean Data
